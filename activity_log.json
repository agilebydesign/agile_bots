{"_default": {"1": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-10T10:09:14.061572"}, "2": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-10T10:09:14.393031", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "The digest gives you 80% of what you need. Only read full rule files when you need the remaining 20%.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (22 total)", "", "1. use_domain_language", "2. consistent_vocabulary", "3. no_defensive_code_in_tests", "4. production_code_clean_functions", "5. bug_fix_test_first", "6. call_production_code_directly", "7. cover_all_behavior_paths", "8. mock_only_boundaries", "9. create_parameterized_tests_for_scenarios", "10. define_fixtures_in_test_file", "11. design_api_through_failing_tests", "12. test_observable_behavior", "13. helper_extraction_and_reuse", "14. match_specification_scenarios", "15. place_imports_at_top", "16. production_code_explicit_dependencies", "17. self_documenting_tests", "18. use_ascii_only", "19. pytest_bdd_orchestrator_pattern", "20. use_class_based_organization", "21. use_exact_variable_names", "22. use_given_when_then_helpers", ""]}}}, "3": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-10T10:11:13.382444"}, "4": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-10T10:11:13.422068", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "The digest gives you 80% of what you need. Only read full rule files when you need the remaining 20%.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (22 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "17. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "18. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "19. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "20. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "21. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "22. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "5": {"action_state": "story_bot.shape.clarify", "status": "completed", "timestamp": "2026-01-10T15:53:11.246747"}, "6": {"action_state": "story_bot.shape.clarify", "status": "completed", "timestamp": "2026-01-10T15:57:44.585637"}, "7": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-12T20:20:15.975352"}, "8": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-12T20:20:16.021849", "outputs": {"error": "Expecting value: line 60 column 35 (char 4621)"}}, "9": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-12T20:22:49.025803"}, "10": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-12T20:22:49.070858", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "11": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-12T20:24:34.564054"}, "12": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-12T20:24:34.602265", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "13": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-12T22:58:08.324026"}, "14": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-12T22:58:08.354084", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "15": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-13T00:04:53.514387"}, "16": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-13T00:04:53.556675", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "17": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-13T00:26:52.378942"}, "18": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-13T00:26:52.412466", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "19": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-13T00:39:14.152771"}, "20": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-13T00:39:14.192838", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "21": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-13T00:39:54.610720"}, "22": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-13T00:39:54.643673", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "**User Request:**", "to follow:", "", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "23": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-13T00:40:37.090817"}, "24": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-13T00:40:37.127101", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "25": {"action_state": "story_bot.scenarios.rules", "status": "started", "timestamp": "2026-01-15T19:24:03.655829"}, "26": {"action_state": "story_bot.scenarios.rules", "status": "completed", "timestamp": "2026-01-15T19:24:03.681352", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **given_describes_state_not_actions**: Given statements describe STATE/PRECONDITIONS, not actions or functionality. Given = what exists before test. When = first action. Then = expected behavior. Example: Given user is logged in (state), not Given user logs in (action).\n  DO: Given describes state/preconditions only. Example: 'Given user is logged in' (state), 'Given character sheet exists' (precondition)\n  DON'T: Don't describe actions or functionality in Given. Example: 'Given user logs in' (action - wrong), 'Given system validates input' (functionality - wrong)\n\n- **use_background_for_common_setup**: Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then). Example: Background: Given user is logged in And character sheet exists (used by 5 scenarios).\n  DO: Background for shared context across multiple scenarios. Example: Given user is logged in (common to all), not scenario-specific setup\n  DON'T: Don't use Background for unique setup or include When/Then. Example: Background with action verbs (wrong), Background for 1 scenario (wrong)\n\n- **scenario_steps_start_with_scenario_specific_given**: Each scenario's Steps start with Given for scenario-specific setup. Background is auto-applied first. Scenario Steps contain setup for THIS scenario only. Example: Background has common setup; Scenario Given has test-specific paths/data.\n  DO: Scenario-specific setup in Steps, common setup in Background. Example: Background: Given Agent initialized; Steps: Given test project at specific/path\n  DON'T: Don't put common setup in scenario Steps or repeat Background. Example: Repeating 'Given Agent initialized' in Steps (wrong - already in Background)\n\n- **scenarios_cover_all_cases**: Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria. Example: Valid input \u2192 success; Boundary value \u2192 validates; Invalid input \u2192 error message.\n  DO: Cover all case types: happy path, edge cases, error cases. Example: User enters valid data \u2192 success; User enters boundary \u2192 validates; User enters invalid \u2192 error\n  DON'T: Don't skip case types. Example: Only happy path scenarios (missing edge and error cases)\n\n- **use_scenario_outline_when_needed**: Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist. Example: Calculate ability modifier with Examples table Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2.\n  DO: Scenario Outline for formulas, domain entities, or data variations. Example: Scenario Outline: Calculate modifier with Examples table showing input\u2192output pairs\n  DON'T: Don't use Scenario Outline for simple behaviors. Example: Scenario Outline: User clicks button (too simple - use regular scenario)\n\n- **write_plain_english_scenarios**: Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at initial scenario writing stage. Example: 'Given user has typed request message start shaping' not 'Given user has typed <request_message>'.\n  DO: Plain English scenarios without variables. Example: 'Given user has attached documents' not 'Given user has attached <documents>'\n  DON'T: Don't use variables or placeholders initially. Example: '<request_message>' variable (wrong at this stage), Scenario Outline (wrong at this stage)\n\n- **scenarios_on_story_docs**: Scenarios must be in story-graph.json (in scenarios or scenario_outlines fields), NOT in separate markdown files. NEVER create feature specification documents. Example: story-graph.json epics[].stories[].scenarios[], not docs/stories/scenarios.md.\n  DO: Add scenarios to story-graph.json. Example: story-graph.json epics[].stories[].scenarios[] array\n  DON'T: Don't create separate scenario files or feature specifications. Example: docs/stories/Epic/Feature/Feature Specification.md (wrong)\n\n- **map_table_columns_to_scenario_parameters**: Map all table columns to scenario parameters bidirectionally. Every column header maps to a Background/When/Then parameter, and every parameter appears as a column. Example: '{payment_system}' parameter \u2192 'Payment System' column.\n  DO: Bidirectional mapping: column \u2194 parameter. Example: 'Payment System' column maps to '{payment_system}' parameter in Background\n  DON'T: Don't omit parameters from table or add columns without parameters. Example: '{payment_system}' in Background but no column (wrong)\n\n- **use_domain_rich_language_in_testing_tables**: Use domain-rich language in testing tables. Replace generic JSON with concrete, descriptive language tied to domain concepts. Real data and examples for all inputs/outputs. Example: 'Payment with amount -50.00 (negative)' not '{\"payment\": {\"amount\": -50}}'.\n  DO: Domain-rich language with concrete examples. Example: 'Payment with amount -50.00 (negative amount violates rule)' not generic JSON\n  DON'T: Don't use generic JSON or abstract descriptions. Example: '{\"payment\": {\"amount\": -50}}' (generic), 'Payment with invalid data' (vague)\n\n- **specify_constants_and_stub_values**: Specify constants where known, use actual values instead of placeholders. Describe stub return values in Givens. Don't parameterize stubbed inputs. Example: 'payment_rules/common/' (constant) not '{rules_path}' (placeholder).\n  DO: Use actual constants, describe stubs explicitly. Example: 'Given Payment validators are stubbed to return {...}' with actual JSON\n  DON'T: Don't parameterize constants or stubbed inputs. Example: '{common_rules_path}' when always 'payment_rules/common/' (wrong)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (10 total)", "", "1. given_describes_state_not_actions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/given_describes_state_not_actions.json)", "2. use_background_for_common_setup (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_background_for_common_setup.json)", "3. scenario_steps_start_with_scenario_specific_given (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenario_steps_start_with_scenario_specific_given.json)", "4. scenarios_cover_all_cases (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_cover_all_cases.json)", "5. use_scenario_outline_when_needed (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_scenario_outline_when_needed.json)", "6. write_plain_english_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/write_plain_english_scenarios.json)", "7. scenarios_on_story_docs (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_on_story_docs.json)", "8. map_table_columns_to_scenario_parameters (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/map_table_columns_to_scenario_parameters.json)", "9. use_domain_rich_language_in_testing_tables (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_domain_rich_language_in_testing_tables.json)", "10. specify_constants_and_stub_values (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/specify_constants_and_stub_values.json)", ""]}}}, "27": {"action_state": "story_bot.scenarios.rules", "status": "started", "timestamp": "2026-01-15T19:24:09.821729"}, "28": {"action_state": "story_bot.scenarios.rules", "status": "completed", "timestamp": "2026-01-15T19:24:09.844737", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **given_describes_state_not_actions**: Given statements describe STATE/PRECONDITIONS, not actions or functionality. Given = what exists before test. When = first action. Then = expected behavior. Example: Given user is logged in (state), not Given user logs in (action).\n  DO: Given describes state/preconditions only. Example: 'Given user is logged in' (state), 'Given character sheet exists' (precondition)\n  DON'T: Don't describe actions or functionality in Given. Example: 'Given user logs in' (action - wrong), 'Given system validates input' (functionality - wrong)\n\n- **use_background_for_common_setup**: Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then). Example: Background: Given user is logged in And character sheet exists (used by 5 scenarios).\n  DO: Background for shared context across multiple scenarios. Example: Given user is logged in (common to all), not scenario-specific setup\n  DON'T: Don't use Background for unique setup or include When/Then. Example: Background with action verbs (wrong), Background for 1 scenario (wrong)\n\n- **scenario_steps_start_with_scenario_specific_given**: Each scenario's Steps start with Given for scenario-specific setup. Background is auto-applied first. Scenario Steps contain setup for THIS scenario only. Example: Background has common setup; Scenario Given has test-specific paths/data.\n  DO: Scenario-specific setup in Steps, common setup in Background. Example: Background: Given Agent initialized; Steps: Given test project at specific/path\n  DON'T: Don't put common setup in scenario Steps or repeat Background. Example: Repeating 'Given Agent initialized' in Steps (wrong - already in Background)\n\n- **scenarios_cover_all_cases**: Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria. Example: Valid input \u2192 success; Boundary value \u2192 validates; Invalid input \u2192 error message.\n  DO: Cover all case types: happy path, edge cases, error cases. Example: User enters valid data \u2192 success; User enters boundary \u2192 validates; User enters invalid \u2192 error\n  DON'T: Don't skip case types. Example: Only happy path scenarios (missing edge and error cases)\n\n- **use_scenario_outline_when_needed**: Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist. Example: Calculate ability modifier with Examples table Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2.\n  DO: Scenario Outline for formulas, domain entities, or data variations. Example: Scenario Outline: Calculate modifier with Examples table showing input\u2192output pairs\n  DON'T: Don't use Scenario Outline for simple behaviors. Example: Scenario Outline: User clicks button (too simple - use regular scenario)\n\n- **write_plain_english_scenarios**: Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at initial scenario writing stage. Example: 'Given user has typed request message start shaping' not 'Given user has typed <request_message>'.\n  DO: Plain English scenarios without variables. Example: 'Given user has attached documents' not 'Given user has attached <documents>'\n  DON'T: Don't use variables or placeholders initially. Example: '<request_message>' variable (wrong at this stage), Scenario Outline (wrong at this stage)\n\n- **scenarios_on_story_docs**: Scenarios must be in story-graph.json (in scenarios or scenario_outlines fields), NOT in separate markdown files. NEVER create feature specification documents. Example: story-graph.json epics[].stories[].scenarios[], not docs/stories/scenarios.md.\n  DO: Add scenarios to story-graph.json. Example: story-graph.json epics[].stories[].scenarios[] array\n  DON'T: Don't create separate scenario files or feature specifications. Example: docs/stories/Epic/Feature/Feature Specification.md (wrong)\n\n- **map_table_columns_to_scenario_parameters**: Map all table columns to scenario parameters bidirectionally. Every column header maps to a Background/When/Then parameter, and every parameter appears as a column. Example: '{payment_system}' parameter \u2192 'Payment System' column.\n  DO: Bidirectional mapping: column \u2194 parameter. Example: 'Payment System' column maps to '{payment_system}' parameter in Background\n  DON'T: Don't omit parameters from table or add columns without parameters. Example: '{payment_system}' in Background but no column (wrong)\n\n- **use_domain_rich_language_in_testing_tables**: Use domain-rich language in testing tables. Replace generic JSON with concrete, descriptive language tied to domain concepts. Real data and examples for all inputs/outputs. Example: 'Payment with amount -50.00 (negative)' not '{\"payment\": {\"amount\": -50}}'.\n  DO: Domain-rich language with concrete examples. Example: 'Payment with amount -50.00 (negative amount violates rule)' not generic JSON\n  DON'T: Don't use generic JSON or abstract descriptions. Example: '{\"payment\": {\"amount\": -50}}' (generic), 'Payment with invalid data' (vague)\n\n- **specify_constants_and_stub_values**: Specify constants where known, use actual values instead of placeholders. Describe stub return values in Givens. Don't parameterize stubbed inputs. Example: 'payment_rules/common/' (constant) not '{rules_path}' (placeholder).\n  DO: Use actual constants, describe stubs explicitly. Example: 'Given Payment validators are stubbed to return {...}' with actual JSON\n  DON'T: Don't parameterize constants or stubbed inputs. Example: '{common_rules_path}' when always 'payment_rules/common/' (wrong)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (10 total)", "", "1. given_describes_state_not_actions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/given_describes_state_not_actions.json)", "2. use_background_for_common_setup (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_background_for_common_setup.json)", "3. scenario_steps_start_with_scenario_specific_given (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenario_steps_start_with_scenario_specific_given.json)", "4. scenarios_cover_all_cases (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_cover_all_cases.json)", "5. use_scenario_outline_when_needed (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_scenario_outline_when_needed.json)", "6. write_plain_english_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/write_plain_english_scenarios.json)", "7. scenarios_on_story_docs (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_on_story_docs.json)", "8. map_table_columns_to_scenario_parameters (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/map_table_columns_to_scenario_parameters.json)", "9. use_domain_rich_language_in_testing_tables (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_domain_rich_language_in_testing_tables.json)", "10. specify_constants_and_stub_values (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/specify_constants_and_stub_values.json)", ""]}}}, "29": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-15T19:43:36.632010"}, "30": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-15T19:43:36.672202", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "31": {"action_state": "story_bot.tests.rules", "status": "started", "timestamp": "2026-01-15T19:44:07.918978"}, "32": {"action_state": "story_bot.tests.rules", "status": "completed", "timestamp": "2026-01-15T19:44:07.947288", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **use_domain_language**: Use Ubiquitous Language (DDD): Same vocabulary in domain model, stories, scenarios, AND code. Class names = domain entities/nouns. Method names = domain responsibilities/verbs. Test names read like plain English stories. Example: test_agent_loads_configuration_when_file_exists (not test_agt_init_sets_vars)\n  DO: Use domain language for classes, methods, and test names. Example: class GatherContextAction, def inject_guardrails(), test_agent_loads_config_when_file_exists\n  DON'T: Don't use generic technical terms or implementation-specific names. Example: class StdioHandler (wrong), def execute_with_guardrails (wrong), test_agt_init_sets_vars (wrong)\n\n- **consistent_vocabulary**: Use ONE word per concept across entire codebase. Pick consistent vocabulary: create (not build/make/construct), verify (not check/assert/validate), load (not fetch/get/retrieve). Use intention-revealing names that describe behavior. Example: create_agent(), verify_initialized(), load_config() - same verbs everywhere\n  DO: Use same word for same concept everywhere. Example: create_agent(), create_config(), create_workspace() - all use 'create'\n  DON'T: Don't mix synonyms for same concept. Example: create_agent() + build_config() + make_workspace() (wrong - pick one verb)\n\n- **no_defensive_code_in_tests**: Tests must NEVER contain guard clauses, defensive conditionals, or fallback paths. We control test setup - if it's wrong, the test MUST fail immediately. Guard clauses hide problems. Tests should assume positive outcomes. Example: Just call the code directly, don't wrap in if-checks\n  DO: Assume correct setup - let test fail if wrong. Example: behavior = Behavior(name='shape') then assert behavior.name == 'shape'\n  DON'T: Don't add if-checks, type guards, or fallback handling in tests. Example: if behavior_file.exists(): (wrong - test should fail if it doesn't)\n\n- **production_code_clean_functions**: Production code functions should do ONE thing, be under 20 lines, and have one level of abstraction. No hidden side effects. Name reveals complete behavior. Extract multiple concerns into separate functions. Example: load_config(), validate_config(), apply_config() - each does one thing\n  DO: Single responsibility, small focused functions. Example: initialize_from_config() calls validate_exists(), load_config(), validate_structure(), apply_config()\n  DON'T: Don't make functions that do multiple unrelated things or are too long. Example: 50-line function that loads, validates, and applies config\n\n- **bug_fix_test_first**: When production code breaks, follow test-first workflow: write failing test, verify failure, fix code, verify success. Never fix bugs without a failing test first. Example: test_mcp_tool_initializes_bot() fails -> fix initialization -> test passes\n  DO: Follow RED-GREEN-PRODUCTION workflow. Example: Write test reproducing bug -> Run test (RED) -> Fix minimal code -> Run test (GREEN) -> Run full suite\n  DON'T: Don't fix bugs directly without failing test first. Example: Editing production code without test -> deploying -> hoping it works (wrong)\n\n- **call_production_code_directly**: Call production code directly in tests. Let tests fail naturally if code doesn't exist. Don't comment out calls, mock business logic, or fake state. Only mock external boundaries. Example: agent = Agent(); agent.initialize() (not agent = Mock())\n  DO: Call production code directly, let it fail naturally. Example: agent = Agent(workspace); agent.initialize(config); assert agent.is_initialized\n  DON'T: Don't mock class under test, comment out calls, or fake state. Example: agent = Mock(spec=Agent) (wrong); agent._initialized = True (wrong)\n\n- **cover_all_behavior_paths**: Cover all behavior paths: normal (happy path), edge cases, and failure scenarios. Each distinct behavior needs its own focused test. Tests must be independent. Example: test_loads_valid_config(), test_loads_empty_config(), test_raises_error_when_file_missing()\n  DO: Test normal, edge, and failure paths separately. Example: test_loads_valid_config() (happy), test_loads_empty_config() (edge), test_raises_when_missing() (failure)\n  DON'T: Don't test only happy path or combine multiple behaviors in one test. Example: Single test for both success and failure (wrong)\n\n- **mock_only_boundaries**: Mock ONLY at architectural boundaries: external APIs, network, uncontrollable services. Don't mock internal business logic, classes under test, or file operations (use temp files). Example: patch('requests.get') (OK); patch('agent.validate') (wrong)\n  DO: Mock only external dependencies you can't control. Example: with patch('requests.get') as mock: (external API - OK to mock)\n  DON'T: Don't mock internal logic, class under test, or file I/O. Example: with patch('agent.validate_config') (wrong - test the logic!)\n\n- **create_parameterized_tests_for_scenarios**: If scenarios have Examples tables, create parameterized tests using @pytest.mark.parametrize. Each row becomes a test case. Don't write single tests that only test one example. Example: @pytest.mark.parametrize('input,expected', [(1, 2), (3, 4)])\n  DO: Create parameterized tests from Examples tables. Example: @pytest.mark.parametrize('paths,count', [(['p1','p2'], 2), (['p3'], 1)])\n  DON'T: Don't hardcode single example or duplicate test methods. Example: def test_with_value_1(): (wrong); def test_with_value_2(): (wrong - use parametrize)\n\n- **define_fixtures_in_test_file**: Define fixtures in the test file, not separate conftest.py. Truly reusable fixtures (file ops, location helpers) go in base conftest.py. Example: @pytest.fixture def workspace_root(tmp_path): return tmp_path / 'workspace'\n  DO: Define fixtures in same test file. Example: @pytest.fixture def config_file(tmp_path): ... (in test_agent.py)\n  DON'T: Don't create separate conftest.py for agent-specific fixtures. Example: src/conftest.py with agent fixtures (wrong - put in test file)\n\n- **design_api_through_failing_tests**: Write tests against the REAL expected API BEFORE implementing code. Tests MUST fail initially. Set up real test data and call real API. Failure reveals complete API design. Example: project = Project(path=path); project.initialize() (doesn't exist yet -> fails -> drives implementation)\n  DO: Write test against real expected API that fails initially. Example: project = Project(path); project.initialize(); assert project.is_ready (fails until implemented)\n  DON'T: Don't use placeholders, dummy values, or skip the failing step. Example: project = 'TODO' (wrong); assuming test passes first (wrong)\n\n- **test_observable_behavior**: Test observable behavior, not implementation details. Verify public API and visible state changes. Don't assert on private methods or internal flags. Example: assert agent.config_path.exists() (observable); not assert agent._internal_flag (private)\n  DO: Test observable outcomes through public API. Example: assert agent.config_path == expected; assert agent.is_initialized (public properties)\n  DON'T: Don't test private state or implementation details. Example: assert agent._initialized (wrong); assert agent._config_cache (wrong)\n\n- **helper_extraction_and_reuse**: Extract duplicate test setup to reusable helper functions. Keep test bodies focused on specific behavior. Example: create_agent_with_config(), create_config_file(), verify_agent_initialized() - reusable across tests\n  DO: Extract duplicate setup to reusable helpers. Example: create_agent_with_config(name, workspace, config) returns initialized Agent\n  DON'T: Don't duplicate setup code across tests. Example: Same 10 lines of setup in every test method (wrong - extract to helper)\n\n- **match_specification_scenarios**: Tests must match specification scenarios exactly. Test names, steps, and assertions verify exactly what the scenario states. Use exact variable names and terminology from specification. Example: agent_name='story_bot' (from spec), not name='bot'\n  DO: Test matches specification exactly. Example: GIVEN config exists, WHEN Agent(agent_name='story_bot'), THEN config_path == agents/base/agent.json\n  DON'T: Don't use different terminology or assert things not in specification. Example: assert agent._internal_flag (not in spec - wrong)\n\n- **place_imports_at_top**: Place all imports at top of test file, after docstrings, before code. Group: stdlib, third-party, then local. Example: import json; import pytest; from mymodule import MyClass\n  DO: All imports at top, grouped by type. Example: import json; import pytest; from agile_bot.bots... import X\n  DON'T: Don't place imports inside functions or after code. Example: def test(): from pathlib import Path (wrong - import inside function)\n\n- **object_oriented_test_helpers**: Consolidate tests around object-oriented helpers/factories (e.g., BotTestHelper test hopper) that build complete domain objects with standard data. Example: helper = BotTestHelper(tmp_path); helper.set_state('shape','clarify'); helper.assert_at_behavior_action('shape','clarify'). Avoid scattering many primitive parameters across parametrize blocks or inline setups.\n  DO: Use shared helper objects to create full test fixtures and assert against complete domain objects, not fragments.\n  DON'T: Do not spread test setup across many primitive parameters or cherry-pick single values from partial objects.\n\n- **production_code_explicit_dependencies**: Production code: make dependencies explicit through constructor injection. Pass all external dependencies as constructor parameters. No hidden global state. Tests easily inject test doubles. Example: Agent(config_loader=loader, domain_graph=graph)\n  DO: Inject all dependencies through constructor. Example: def __init__(self, config_loader, domain_graph): self._loader = config_loader\n  DON'T: Don't access globals, singletons, or create dependencies internally. Example: self._loader = ConfigLoader() (wrong - creates internally)\n\n- **self_documenting_tests**: Tests are self-documenting through code structure. Don't add verbose comments explaining failures. Imports, calls, and assertions show the API design. Let code speak for itself. Example: generator = MCPServerGenerator(bot_name, config_path); server = generator.generate_server()\n  DO: Let code structure document the test. Example: generator = MCPServerGenerator(name, config); file = generator.generate() - API is clear\n  DON'T: Don't add verbose comments explaining obvious things. Example: # This will fail because API doesn't exist yet (unnecessary)\n\n- **standard_test_data_sets**: Use standard, named test data sets across tests instead of recreating ad-hoc values. Example: STANDARD_STATE = {...}; helper.set_state(...); assert helper.get_state() == STANDARD_STATE.\n  DO: Define canonical data once (helper constants/factories) and reuse it so every test exercises the full domain object.\n  DON'T: Do not create new ad-hoc values per test or assert only one field from a complex object.\n\n- **assert_full_results**: Assert full domain results (state/log/graph objects), not single cherry-picked fields. Example: assert helper.get_state() == STANDARD_STATE, not assert helper.get_state()['current'] == 'shape.clarify'.\n  DO: Compare entire objects/dicts/dataclasses against standard data fixtures.\n  DON'T: Do not assert single fields or lengths when validating complex results.\n\n- **use_ascii_only**: All test code must use ASCII-only characters. No Unicode symbols, emojis, or special characters. Use plain ASCII alternatives. Example: print('[PASS] Success') not print('[checkmark] Success')\n  DO: Use ASCII-only characters. Example: print('[PASS] Agent initialized'); print('[ERROR] Config not found')\n  DON'T: Don't use Unicode or emojis. Example: print('[checkmark] Done') (wrong); print('[green_check] OK') (wrong)\n\n- **pytest_bdd_orchestrator_pattern**: Use pytest with orchestrator pattern for story-based tests. NO FEATURE FILES. Test classes contain orchestrator methods (under 20 lines) showing Given-When-Then flow by calling helper functions. Example: def test_agent_loads_config(): given_config_exists(); agent = when_agent_initialized(); then_agent_is_configured(agent)\n  DO: Orchestrator pattern: test shows flow, delegates to helpers. Example: # Given; create_config_file(); # When; agent.initialize(); # Then; assert agent.is_initialized\n  DON'T: Don't use feature files or inline complex setup. Example: @given('config exists') def step(): ... (wrong - use pytest directly)\n\n- **use_class_based_organization**: Test structure matches story graph: file = sub-epic (test_<sub_epic>.py), class = story (Test<ExactStoryName>), method = scenario (test_<scenario_snake_case>). Classes in story map order. Example: test_generate_bot_tools.py, class TestGenerateBotTools, def test_generator_creates_tool_for_test_bot\n  DO: Map story hierarchy to test structure exactly. Example: Sub-epic 'Generate Bot Tools' -> test_generate_bot_tools.py, Story 'Generate Bot Tools' -> TestGenerateBotTools\n  DON'T: Don't use generic/abbreviated names or wrong order. Example: class TestToolGen (wrong - use TestGenerateBotTools)\n\n- **use_exact_variable_names**: Use exact variable names from specification scenarios. When spec mentions agent_name, workspace_root, config_path - use those exact names in tests and production code. Example: agent_name = 'story_bot' (from spec), not name = 'story_bot'\n  DO: Use exact names from specification in tests and production. Example: agent_name, workspace_root, config_path - all from spec\n  DON'T: Don't use different names than specification. Example: name = 'bot' when spec says agent_name (wrong)\n\n- **use_given_when_then_helpers**: Use reusable helper functions instead of inline code blocks of 4+ lines. Optimize for reusability, not exact step names. Place helpers at correct scope: story-level in class, sub-epic in module, epic in separate file. Example: given_config_exists(), when_agent_initialized(), then_agent_is_configured()\n  DO: Use Given/When/Then helper functions for setup, action, assertion. Example: given_bot_config_exists(); bot = when_bot_instantiated(); then_bot_uses_correct_directories(bot)\n  DON'T: Don't use inline operations of 4+ lines. Example: config_dir = ...; config_dir.mkdir(); config_file = ...; config_file.write_text() (wrong - extract to helper)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (25 total)", "", "1. use_domain_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_domain_language.json)", "2. consistent_vocabulary (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/consistent_vocabulary.json)", "3. no_defensive_code_in_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/no_defensive_code_in_tests.json)", "4. production_code_clean_functions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_clean_functions.json)", "5. bug_fix_test_first (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/bug_fix_test_first.json)", "6. call_production_code_directly (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/call_production_code_directly.json)", "7. cover_all_behavior_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/cover_all_behavior_paths.json)", "8. mock_only_boundaries (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/mock_only_boundaries.json)", "9. create_parameterized_tests_for_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/create_parameterized_tests_for_scenarios.json)", "10. define_fixtures_in_test_file (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/define_fixtures_in_test_file.json)", "11. design_api_through_failing_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/design_api_through_failing_tests.json)", "12. test_observable_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/test_observable_behavior.json)", "13. helper_extraction_and_reuse (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/helper_extraction_and_reuse.json)", "14. match_specification_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/match_specification_scenarios.json)", "15. place_imports_at_top (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/place_imports_at_top.json)", "16. object_oriented_test_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/object_oriented_test_helpers.json)", "17. production_code_explicit_dependencies (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/production_code_explicit_dependencies.json)", "18. self_documenting_tests (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/self_documenting_tests.json)", "19. standard_test_data_sets (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/standard_test_data_sets.json)", "20. assert_full_results (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/assert_full_results.json)", "21. use_ascii_only (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_ascii_only.json)", "22. pytest_bdd_orchestrator_pattern (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/pytest_bdd_orchestrator_pattern.json)", "23. use_class_based_organization (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_class_based_organization.json)", "24. use_exact_variable_names (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_exact_variable_names.json)", "25. use_given_when_then_helpers (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/tests/rules/use_given_when_then_helpers.json)", ""]}}}, "33": {"action_state": "story_bot.scenarios.rules", "status": "started", "timestamp": "2026-01-15T19:45:47.678766"}, "34": {"action_state": "story_bot.scenarios.rules", "status": "completed", "timestamp": "2026-01-15T19:45:47.707811", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **given_describes_state_not_actions**: Given statements describe STATE/PRECONDITIONS, not actions or functionality. Given = what exists before test. When = first action. Then = expected behavior. Example: Given user is logged in (state), not Given user logs in (action).\n  DO: Given describes state/preconditions only. Example: 'Given user is logged in' (state), 'Given character sheet exists' (precondition)\n  DON'T: Don't describe actions or functionality in Given. Example: 'Given user logs in' (action - wrong), 'Given system validates input' (functionality - wrong)\n\n- **use_background_for_common_setup**: Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then). Example: Background: Given user is logged in And character sheet exists (used by 5 scenarios).\n  DO: Background for shared context across multiple scenarios. Example: Given user is logged in (common to all), not scenario-specific setup\n  DON'T: Don't use Background for unique setup or include When/Then. Example: Background with action verbs (wrong), Background for 1 scenario (wrong)\n\n- **scenario_steps_start_with_scenario_specific_given**: Each scenario's Steps start with Given for scenario-specific setup. Background is auto-applied first. Scenario Steps contain setup for THIS scenario only. Example: Background has common setup; Scenario Given has test-specific paths/data.\n  DO: Scenario-specific setup in Steps, common setup in Background. Example: Background: Given Agent initialized; Steps: Given test project at specific/path\n  DON'T: Don't put common setup in scenario Steps or repeat Background. Example: Repeating 'Given Agent initialized' in Steps (wrong - already in Background)\n\n- **scenarios_cover_all_cases**: Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria. Example: Valid input \u2192 success; Boundary value \u2192 validates; Invalid input \u2192 error message.\n  DO: Cover all case types: happy path, edge cases, error cases. Example: User enters valid data \u2192 success; User enters boundary \u2192 validates; User enters invalid \u2192 error\n  DON'T: Don't skip case types. Example: Only happy path scenarios (missing edge and error cases)\n\n- **use_scenario_outline_when_needed**: Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist. Example: Calculate ability modifier with Examples table Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2.\n  DO: Scenario Outline for formulas, domain entities, or data variations. Example: Scenario Outline: Calculate modifier with Examples table showing input\u2192output pairs\n  DON'T: Don't use Scenario Outline for simple behaviors. Example: Scenario Outline: User clicks button (too simple - use regular scenario)\n\n- **write_plain_english_scenarios**: Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at initial scenario writing stage. Example: 'Given user has typed request message start shaping' not 'Given user has typed <request_message>'.\n  DO: Plain English scenarios without variables. Example: 'Given user has attached documents' not 'Given user has attached <documents>'\n  DON'T: Don't use variables or placeholders initially. Example: '<request_message>' variable (wrong at this stage), Scenario Outline (wrong at this stage)\n\n- **scenarios_on_story_docs**: Scenarios must be in story-graph.json (in scenarios or scenario_outlines fields), NOT in separate markdown files. NEVER create feature specification documents. Example: story-graph.json epics[].stories[].scenarios[], not docs/stories/scenarios.md.\n  DO: Add scenarios to story-graph.json. Example: story-graph.json epics[].stories[].scenarios[] array\n  DON'T: Don't create separate scenario files or feature specifications. Example: docs/stories/Epic/Feature/Feature Specification.md (wrong)\n\n- **map_table_columns_to_scenario_parameters**: Map all table columns to scenario parameters bidirectionally. Every column header maps to a Background/When/Then parameter, and every parameter appears as a column. Example: '{payment_system}' parameter \u2192 'Payment System' column.\n  DO: Bidirectional mapping: column \u2194 parameter. Example: 'Payment System' column maps to '{payment_system}' parameter in Background\n  DON'T: Don't omit parameters from table or add columns without parameters. Example: '{payment_system}' in Background but no column (wrong)\n\n- **use_domain_rich_language_in_testing_tables**: Use domain-rich language in testing tables. Replace generic JSON with concrete, descriptive language tied to domain concepts. Real data and examples for all inputs/outputs. Example: 'Payment with amount -50.00 (negative)' not '{\"payment\": {\"amount\": -50}}'.\n  DO: Domain-rich language with concrete examples. Example: 'Payment with amount -50.00 (negative amount violates rule)' not generic JSON\n  DON'T: Don't use generic JSON or abstract descriptions. Example: '{\"payment\": {\"amount\": -50}}' (generic), 'Payment with invalid data' (vague)\n\n- **specify_constants_and_stub_values**: Specify constants where known, use actual values instead of placeholders. Describe stub return values in Givens. Don't parameterize stubbed inputs. Example: 'payment_rules/common/' (constant) not '{rules_path}' (placeholder).\n  DO: Use actual constants, describe stubs explicitly. Example: 'Given Payment validators are stubbed to return {...}' with actual JSON\n  DON'T: Don't parameterize constants or stubbed inputs. Example: '{common_rules_path}' when always 'payment_rules/common/' (wrong)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (10 total)", "", "1. given_describes_state_not_actions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/given_describes_state_not_actions.json)", "2. use_background_for_common_setup (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_background_for_common_setup.json)", "3. scenario_steps_start_with_scenario_specific_given (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenario_steps_start_with_scenario_specific_given.json)", "4. scenarios_cover_all_cases (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_cover_all_cases.json)", "5. use_scenario_outline_when_needed (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_scenario_outline_when_needed.json)", "6. write_plain_english_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/write_plain_english_scenarios.json)", "7. scenarios_on_story_docs (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_on_story_docs.json)", "8. map_table_columns_to_scenario_parameters (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/map_table_columns_to_scenario_parameters.json)", "9. use_domain_rich_language_in_testing_tables (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_domain_rich_language_in_testing_tables.json)", "10. specify_constants_and_stub_values (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/specify_constants_and_stub_values.json)", ""]}}}, "35": {"action_state": "story_bot.scenarios.rules", "status": "started", "timestamp": "2026-01-15T19:46:00.950416"}, "36": {"action_state": "story_bot.scenarios.rules", "status": "completed", "timestamp": "2026-01-15T19:46:00.979833", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **given_describes_state_not_actions**: Given statements describe STATE/PRECONDITIONS, not actions or functionality. Given = what exists before test. When = first action. Then = expected behavior. Example: Given user is logged in (state), not Given user logs in (action).\n  DO: Given describes state/preconditions only. Example: 'Given user is logged in' (state), 'Given character sheet exists' (precondition)\n  DON'T: Don't describe actions or functionality in Given. Example: 'Given user logs in' (action - wrong), 'Given system validates input' (functionality - wrong)\n\n- **use_background_for_common_setup**: Use Background for repeated Given steps across 3+ scenarios. Background contains only Given/And steps (no When/Then). Example: Background: Given user is logged in And character sheet exists (used by 5 scenarios).\n  DO: Background for shared context across multiple scenarios. Example: Given user is logged in (common to all), not scenario-specific setup\n  DON'T: Don't use Background for unique setup or include When/Then. Example: Background with action verbs (wrong), Background for 1 scenario (wrong)\n\n- **scenario_steps_start_with_scenario_specific_given**: Each scenario's Steps start with Given for scenario-specific setup. Background is auto-applied first. Scenario Steps contain setup for THIS scenario only. Example: Background has common setup; Scenario Given has test-specific paths/data.\n  DO: Scenario-specific setup in Steps, common setup in Background. Example: Background: Given Agent initialized; Steps: Given test project at specific/path\n  DON'T: Don't put common setup in scenario Steps or repeat Background. Example: Repeating 'Given Agent initialized' in Steps (wrong - already in Background)\n\n- **scenarios_cover_all_cases**: Scenarios must cover happy path, edge cases, and error cases based on acceptance criteria. Example: Valid input \u2192 success; Boundary value \u2192 validates; Invalid input \u2192 error message.\n  DO: Cover all case types: happy path, edge cases, error cases. Example: User enters valid data \u2192 success; User enters boundary \u2192 validates; User enters invalid \u2192 error\n  DON'T: Don't skip case types. Example: Only happy path scenarios (missing edge and error cases)\n\n- **use_scenario_outline_when_needed**: Use Scenario Outline with Examples when story warrants concrete data: formulas need validation, domain has named entities, parameter variations exist. Example: Calculate ability modifier with Examples table Rank 10\u21920, Rank 12\u2192+1, Rank 14\u2192+2.\n  DO: Scenario Outline for formulas, domain entities, or data variations. Example: Scenario Outline: Calculate modifier with Examples table showing input\u2192output pairs\n  DON'T: Don't use Scenario Outline for simple behaviors. Example: Scenario Outline: User clicks button (too simple - use regular scenario)\n\n- **write_plain_english_scenarios**: Write scenarios in plain English. NO variables, NO placeholders, NO Scenario Outlines, NO Examples tables at initial scenario writing stage. Example: 'Given user has typed request message start shaping' not 'Given user has typed <request_message>'.\n  DO: Plain English scenarios without variables. Example: 'Given user has attached documents' not 'Given user has attached <documents>'\n  DON'T: Don't use variables or placeholders initially. Example: '<request_message>' variable (wrong at this stage), Scenario Outline (wrong at this stage)\n\n- **scenarios_on_story_docs**: Scenarios must be in story-graph.json (in scenarios or scenario_outlines fields), NOT in separate markdown files. NEVER create feature specification documents. Example: story-graph.json epics[].stories[].scenarios[], not docs/stories/scenarios.md.\n  DO: Add scenarios to story-graph.json. Example: story-graph.json epics[].stories[].scenarios[] array\n  DON'T: Don't create separate scenario files or feature specifications. Example: docs/stories/Epic/Feature/Feature Specification.md (wrong)\n\n- **map_table_columns_to_scenario_parameters**: Map all table columns to scenario parameters bidirectionally. Every column header maps to a Background/When/Then parameter, and every parameter appears as a column. Example: '{payment_system}' parameter \u2192 'Payment System' column.\n  DO: Bidirectional mapping: column \u2194 parameter. Example: 'Payment System' column maps to '{payment_system}' parameter in Background\n  DON'T: Don't omit parameters from table or add columns without parameters. Example: '{payment_system}' in Background but no column (wrong)\n\n- **use_domain_rich_language_in_testing_tables**: Use domain-rich language in testing tables. Replace generic JSON with concrete, descriptive language tied to domain concepts. Real data and examples for all inputs/outputs. Example: 'Payment with amount -50.00 (negative)' not '{\"payment\": {\"amount\": -50}}'.\n  DO: Domain-rich language with concrete examples. Example: 'Payment with amount -50.00 (negative amount violates rule)' not generic JSON\n  DON'T: Don't use generic JSON or abstract descriptions. Example: '{\"payment\": {\"amount\": -50}}' (generic), 'Payment with invalid data' (vague)\n\n- **specify_constants_and_stub_values**: Specify constants where known, use actual values instead of placeholders. Describe stub return values in Givens. Don't parameterize stubbed inputs. Example: 'payment_rules/common/' (constant) not '{rules_path}' (placeholder).\n  DO: Use actual constants, describe stubs explicitly. Example: 'Given Payment validators are stubbed to return {...}' with actual JSON\n  DON'T: Don't parameterize constants or stubbed inputs. Example: '{common_rules_path}' when always 'payment_rules/common/' (wrong)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (10 total)", "", "1. given_describes_state_not_actions (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/given_describes_state_not_actions.json)", "2. use_background_for_common_setup (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_background_for_common_setup.json)", "3. scenario_steps_start_with_scenario_specific_given (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenario_steps_start_with_scenario_specific_given.json)", "4. scenarios_cover_all_cases (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_cover_all_cases.json)", "5. use_scenario_outline_when_needed (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_scenario_outline_when_needed.json)", "6. write_plain_english_scenarios (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/write_plain_english_scenarios.json)", "7. scenarios_on_story_docs (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/scenarios_on_story_docs.json)", "8. map_table_columns_to_scenario_parameters (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/map_table_columns_to_scenario_parameters.json)", "9. use_domain_rich_language_in_testing_tables (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/use_domain_rich_language_in_testing_tables.json)", "10. specify_constants_and_stub_values (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/scenarios/rules/specify_constants_and_stub_values.json)", ""]}}}, "37": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T19:46:48.519974"}, "38": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T19:46:48.545107", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "39": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T19:47:12.654970"}, "40": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T19:47:12.680628", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "41": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T19:48:12.698412"}, "42": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T19:48:12.726502", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "43": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T19:49:39.989741"}, "44": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T19:49:40.019861", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "45": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T19:50:03.894207"}, "46": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T19:50:03.920752", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "47": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T19:51:00.325824"}, "48": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T19:51:00.354035", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "49": {"action_state": "story_bot.prioritization.rules", "status": "started", "timestamp": "2026-01-15T19:55:57.767181"}, "50": {"action_state": "story_bot.prioritization.rules", "status": "completed", "timestamp": "2026-01-15T19:55:57.794040", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **map_sequential_spine_vs_optional_paths**: When mapping stories, carefully distinguish between sequential spine (essential path) and optional paths, alternate routes, or additional functionality that is not strictly essential. Sequential stories form the mandatory flow; optional stories are alternatives, enhancements, or non-essential features.\n  DO: Identify the essential spine and mark optional paths clearly\n  DON'T: Don't mark everything as sequential, don't omit optional markers\n\n- **design_vertical_slice_increments**: Create increments that are vertical slices that deliver end-to-end working flows across multiple features/epics, NOT horizontal layers that complete one feature/epic at a time. Each increment must demonstrate complete working flow from start to finish.\n  DO: Design increments as vertical slices - end-to-end flows across multiple epics/features\n  DON'T: Don't design increments as horizontal layers, don't complete one feature/epic at a time\n\n- **apply_quality_tradeoffs_for_minimal_spine**: Apply quality trade-offs to create thin slicing spine and later increments. Decide what quality the spine will have, what parts will be manual, what logic can be excluded, and how to prioritize adding quality in later increments.\n  DO: Make deliberate quality trade-offs to minimize spine size\n  DON'T: Don't build full quality into thin slicing spine, don't skip documenting trade-offs\n\n- **identify_marketable_increments**: Identify marketable increments of value during prioritization. Name increments with business value terms that stakeholders understand, not technical implementation terms.\n  DO: Name increments with business value terms\n  DON'T: Don't use technical implementation terms in increment names\n\n- **prioritize_architectural_risk_validation**: Prioritize early increments to validate architectural risks and technology decisions. Build risky integrations, test unfamiliar technologies, and validate solution feasibility early to avoid late-stage surprises.\n  DO: Prioritize architectural risk validation in early increments\n  DON'T: Don't defer architectural risks to later increments, don't assume integrations will work without validation", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (5 total)", "", "1. map_sequential_spine_vs_optional_paths (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/prioritization/rules/map_sequential_spine_vs_optional_paths.json)", "2. design_vertical_slice_increments (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/prioritization/rules/design_vertical_slice_increments.json)", "3. apply_quality_tradeoffs_for_minimal_spine (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/prioritization/rules/apply_quality_tradeoffs_for_minimal_spine.json)", "4. identify_marketable_increments (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/prioritization/rules/identify_marketable_increments.json)", "5. prioritize_architectural_risk_validation (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/prioritization/rules/prioritize_architectural_risk_validation.json)", ""]}}}, "51": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:06:17.278306"}, "52": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:06:17.307325", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "53": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:07:34.021921"}, "54": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:07:34.049365", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "55": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:08:22.343155"}, "56": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:08:22.369760", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "57": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:10:32.118088"}, "58": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:10:32.147071", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "59": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:11:02.926551"}, "60": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:11:02.959326", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "61": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:14:42.286323"}, "62": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:14:42.311943", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "63": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:16:14.863949"}, "64": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:16:14.891126", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "65": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:16:36.477828"}, "66": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:16:36.503750", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "67": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:18:05.726244"}, "68": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:18:05.754790", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "69": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:19:54.585720"}, "70": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:19:54.612437", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}, "71": {"action_state": "story_bot.shape.rules", "status": "started", "timestamp": "2026-01-15T20:20:04.591899"}, "72": {"action_state": "story_bot.shape.rules", "status": "completed", "timestamp": "2026-01-15T20:20:04.618103", "outputs": {"instructions": {"base_instructions": ["**Look for context in the following locations:**", "- in this message and chat history", "- in `C:/dev/augmented-teams/agile_bot/docs/context/`", "- generated files in `C:/dev/augmented-teams/agile_bot/docs/stories/`", "  clarification.json, strategy.json", "", "CRITICAL: This is the rules action - it loads rules for AI context. DO NOT run validation.", "CRITICAL: You MUST systematically read each rule file listed below using the read_file tool BEFORE acting on the user's message.", "Read ALL rule files first, then apply them to the user's request.", "Each rule file path is provided - use read_file to load the complete rule content including examples.", "After reading all rules, act on the user's message following ALL the rules you just read.", "", "CRITICAL: When reporting validation results, use this EXACT format:", "For each rule checked, report: Rule Name | PASS or FAIL | If FAIL, explain why in one sentence", "Example: prefer_object_model_over_config | PASS", "Example: eliminate_duplication | FAIL | Same logic repeated in lines 45-50 and 78-83", "Keep it simple: just tell the user what passed, what failed, and if it failed, why.", "", "Rules to follow:\n\n- **verb_noun_format**: Use verb-noun format consistently across all hierarchy levels. Actor --> verb noun [qualifiers]. Actor is documented separately, NOT in the name. Focus on specific actions with context.\n  DO: Use specific verb-noun format with actor documented separately. Example: 'Places Order' with actor=Customer\n  DON'T: Don't include actor in name or use generic operations. Example: 'Customer Places Order' (WRONG) \u2192 'Places Order' with actor=Customer (CORRECT)\n\n- **active_business_and_behavioral_language**: Use active business language focused on user/system behavior. Describe what actors do with clear action verbs, not technical implementation or passive constructions.\n  DO: Use active voice with business language. Example: 'User submits order' (active voice, business language describing what actor does)\n  DON'T: Don't use passive voice or technical implementation language. Example: 'Order is submitted' (passive voice, unclear actor) \u2192 'User submits order' (active voice, clear actor)\n\n- **outcome_oriented_language**: Use outcome-oriented language over mechanism-oriented language. Focus on what is created or achieved, not how it's shown or communicated.\n  DO: Focus on outcomes and artifacts, not mechanisms. Example: 'Power Activation Animation' not 'Visualizing Power Activation'\n  DON'T: Don't focus on communication mechanisms. Example: 'Showing Combat Results' (mechanism) \u2192 'Combat Outcome Feedback' (outcome)\n\n- **lightweight_and_precise**: Create lightweight but precise documentation during shaping. Focus on structure and scope, not detailed specifications.\n  DO: Keep documentation lightweight and easy to walk through. Example: '(E) Manage Orders \u2192 (SE) Place Order \u2192 (S) Validate Order Items' (shows hierarchy, not specs)\n  DON'T: Don't over-elaborate or add detailed specifications during shaping. Example: '(E) Manage Orders \u2192 Detailed API specs, database schema, UI mockups' (TOO MUCH)\n\n- **valuable**: Stories must deliver independent value as complete functional accomplishments. Balance value with testability - stories should be valuable enough to matter but small enough to deliver quickly. Not just data access or isolated operations.\n  DO: Create stories that deliver independent value. Example: 'User --> loads story graph' (value: see story structure)\n  DON'T: Don't create stories without independent value or complete outcomes. Example: 'System --> reads all epics from diagram' (no value - what happens with the data?)\n\n- **small_and_testable**: Stories must be testable as complete interactions and deliverable independently. Balance testability with maintaining value and behavioral focus - stories should be small enough to test but large enough to matter.\n  DO: Create stories that can be tested and delivered independently. Example: 'Customer places order' (testable with clear acceptance criteria: order created, payment processed)\n  DON'T: Don't create stories that can't be tested or delivered independently. Example: 'Add order button' (not testable - can't verify independently without full order flow context)\n\n- **user_and_system_behavior**: Stories should capture both user and system behavior. User-facing stories show user actions with system responses. System stories capture system-to-system interactions and should be marked with story_type: 'system'. NOTE: This rule only applies when strategy decisions in planning.json specify flow_scope_and_granularity as 'Integration boundary level' or 'Intra-system level', OR drill_down_approach includes 'Dig deep on system interactions' or 'Dig deep on architectural pieces'. Check {project_area}/docs/stories/planning.json for these decisions.\n  DO: Show both user and system behavior, mark system-to-system stories. Example: 'User submits order, System validates payment'\n  DON'T: Don't show incomplete stories 'User enters order data' (WRONG - missing: what does system do in response?)\n\n- **story_map_existing_code**: When creating story maps from code, start with the outermost layer (entry points), analyze operations, create epics from higher-order goals, and lay out the story journey.\n  DO: Start with entry points and trace to epics and stories. Example: Operations 'render-outline, render-increments' \u2192 Goal 'Render StoryGraph' \u2192 Epic 'Render StoryGraph'\n  DON'T: Don't start with internal classes or create epics from class structure. Example: Creating epics from class structure (WRONG) \u2192 Create epics from goals (CORRECT)", "", "CRITICAL: The rules digest above contains everything you need to get started.", "", "WORKFLOW:", "1. Read the rules digest above (descriptions + key principles)", "2. Apply rules to the user's request", "3. IF you need clarity on a specific rule (examples, edge cases, detailed patterns):", "   - Use read_file tool to read that specific rule file", "   - The full rule has detailed examples and detection patterns", "4. Cite rule names when making decisions", "", "Please make sure to validate content against the rules above, as well as the more detailed version of the rule files linked below.", "", "When analyzing code, focus on finding violations and cite the specific rule names.", "", "CRITICAL: You MUST read the file `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and display its ENTIRE contents in a markdown code fence to the user.", "Use the read_file tool to read `C:\\dev\\augmented-teams\\agile_bot\\.cursor\\display\\status.md` and then display the full contents.", "DO NOT just reference the file - actually READ it and SHOW its contents to the user."], "clarification": {"shape": {"key_questions": {"answers": {"What is the scope of this work?": "The Generate Bot Tools (from Increment 1: User Manually Drops Config In to AI Chat). This story creates the foundational MCP bot tool that routes AI chat requests to bot behaviors and actions, enabling all subsequent MCP-based interactions.", "Who are the target users?": "The Three primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "What is the first priority action?": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations.", "Workspace": "THREE primary user groups: (1) AI Agents - interact via MCP tools to execute bot behaviors and access knowledge graphs, (2) Developers - use CLI and panel interfaces to navigate workflows, manage scope, and execute actions, (3) Bot System - internal behaviors that orchestrate workflows, track state, and coordinate between actions.", "Filter": "Building the comprehensive agile bot system that enables AI agents and developers to manage software development workflows. The system includes: (1) Bot infrastructure with behavior-based workflows (clarify, strategy, build, validate, render actions), (2) MCP server integration for AI tool invocation, (3) Multiple interface options (CLI, VS Code panel), (4) Knowledge graph management for story mapping and CRC modeling, (5) Scope filtering and navigation capabilities, (6) Automated validation with rule scanners, and (7) Activity tracking across all operations."}}, "evidence": {"required": ["Requirements doc", "User interviews", "Product roadmap"], "provided": {}}, "context": []}}, "display_content": ["", "## Rules Available (8 total)", "", "1. verb_noun_format (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/verb_noun_format.json)", "2. active_business_and_behavioral_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/active_business_and_behavioral_language.json)", "3. outcome_oriented_language (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/outcome_oriented_language.json)", "4. lightweight_and_precise (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/lightweight_and_precise.json)", "5. valuable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/valuable.json)", "6. small_and_testable (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/small_and_testable.json)", "7. user_and_system_behavior (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/user_and_system_behavior.json)", "8. story_map_existing_code (C:/dev/augmented-teams/agile_bot/bots/story_bot/behaviors/shape/rules/story_map_existing_code.json)", ""]}}}}}